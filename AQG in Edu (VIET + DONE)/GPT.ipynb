{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = GPT4AllEmbeddings()\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(filename: str, content: str):\n",
    "    with open(f\"{filename}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=os.environ.get(\"LLAMA_API_KEY\"),\n",
    "#     base_url=\"https://api.llama-api.com/\"\n",
    "# )\n",
    "# model_name = \"llama3.2-3b\"\n",
    "\n",
    "def ask_gpt(prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def chunking(sauce: str, chunk_size, chunk_overlap):\n",
    "    print(\"Begin chunking...\")\n",
    "    loader = PyPDFLoader(sauce)\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    print(\"Done!\")\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "# Path to the saved vector store\n",
    "faiss_index_path = \"faiss_index\"\n",
    "if os.path.exists(faiss_index_path):\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    all_splits = chunking(\"trietly.pdf\", 1800, 200)\n",
    "    print(\"Begin vector storing...\")\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "    print(\"Done vector storing!\")\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_res = '''\n",
    "Đọc thông tin và các ví dụ sau:\n",
    "________________\n",
    "1. Thông tin\n",
    "________________\n",
    "{context}\n",
    "________________\n",
    "2. Ví dụ\n",
    "- Văn bản: Môi trường là tổng thể các yếu tố tự nhiên và nhân tạo xung quanh con người, ảnh hưởng đến sự sống và phát triển của mọi sinh vật.\n",
    "Câu hỏi: Môi trường là gì?\n",
    "- Văn bản: Yêu thương con người là sự quan tâm, giúp đỡ người khác, làm những điều tốt đẹp cho người khác, nhất là những người khó khăn, hoạn nạn.\n",
    "Câu hỏi: Thế nào là yêu thương con người?\n",
    "- Văn bản: Chương trình Cặp lá yêu thương là dự án hỗ trợ các em học sinh có hoàn cảnh khó khăn, vươn lên trong cuộc sống để tiếp tục tới trường.\n",
    "Câu hỏi: Tìm hiểu và cho biết một chương trình giải trí với ý nghĩa thể hiện tình yêu thương của con người với những hoàn cảnh khó khăn?\n",
    "- Văn bản: Yêu thương con người là tình cảm quý giá, một giá trị nhân văn và là truyền thống quý báu của dân tộc mà mỗi chúng ta cần phải giữ gìn và phát huy.\n",
    "Câu hỏi: Giá trị của tình yêu thương đối với con người và xã hội là gì?\n",
    "- Văn bản: Tình yêu thương con người mang lại niềm vui, sự tin tưởng vào bản thân và cuộc sống. \n",
    "Câu hỏi: Yêu thương con người chúng ta sẽ nhận được điều gì?\n",
    "________________\n",
    "Hãy đặt khoảng 5 câu hỏi cho văn bản dưới đây.\n",
    "{statement}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "Done compiling!\n"
     ]
    }
   ],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    statement: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    print(\"Begin retriving!\")\n",
    "    docs = retriever.invoke(state[\"statement\"])\n",
    "    print(\"Done retrieving!\")\n",
    "    return {\"context\": docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    print(\"Begin generating!\")\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_res.format(statement = state[\"statement\"], context = docs_content)\n",
    "    messages.replace(\"\\t\", \" \")\n",
    "    logging(\"Prompt\", messages)\n",
    "    response = ask_gpt(messages)\n",
    "    print(\"Done generating!\")\n",
    "    return {\"answer\": response}\n",
    "\n",
    "print(\"Compiling...\")\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "print(\"Done compiling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin retriving!\n",
      "Done retrieving!\n",
      "Begin generating!\n",
      "Done generating!\n"
     ]
    }
   ],
   "source": [
    "statement = '''\n",
    "Tuổi trẻ là tài sản lớn nhất, phải quý trọng thời gian, đừng sợ nghèo khó, gian nan. \n",
    "Hãy dùng tuổi trẻ để bồi dưỡng bản thân, hiểu được cái gì là đáng quý, biết được thứ nên đầu tư, chỗ nên tiết kiệm. \n",
    "Đó chính là điểm mấu chốt của bài học làm giàu, chìa khóa để thay đổi cuộc đời.\n",
    "'''\n",
    "\n",
    "response = graph.invoke({\"statement\": statement})\n",
    "logging(\"result\", response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
