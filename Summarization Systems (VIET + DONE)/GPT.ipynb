{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "sys_prompt = '''\n",
    "Summarize or rewrite the following text using dashes to list key points and crucial details, like data and news. \n",
    "Avoid duplicate points, and ensure the context is preserved by not over-simplifying or over-summarizing sentences. \n",
    "Return the result in raw text format.\n",
    "'''\n",
    "\n",
    "def ask_gpt(prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": sys_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=4096\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def logging(filename: str, content: str):\n",
    "    with open(f\"{filename}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunking(transcript: str): # tokens\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        model_name=\"gpt-4o\", \n",
    "        chunk_size=5000,\n",
    "        chunk_overlap=500\n",
    "    )\n",
    "    return text_splitter.split_text(transcript)\n",
    "\n",
    "def summarize(chapters):\n",
    "    concatenate = \"\"\n",
    "    for chapter in chapters:\n",
    "        summary = ask_gpt(chapter)\n",
    "        concatenate = concatenate + \"\\n\" + summary\n",
    "    return summary\n",
    "\n",
    "transcript = \"\"\n",
    "with open(\"transcript.txt\") as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "while True:\n",
    "    chapters = chunking(transcript)\n",
    "    transcript = summarize(chapters)\n",
    "    if len(chapters) == 1:\n",
    "        break\n",
    "\n",
    "logging(\"result\", transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
