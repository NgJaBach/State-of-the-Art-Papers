{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11125995,"sourceType":"datasetVersion","datasetId":6938589}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nwandb_key = UserSecretsClient().get_secret(\"wannabe\")\n\nwandb.login(key=wandb_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:06:39.627807Z","iopub.execute_input":"2025-03-23T12:06:39.628128Z","iopub.status.idle":"2025-03-23T12:06:48.259324Z","shell.execute_reply.started":"2025-03-23T12:06:39.628099Z","shell.execute_reply":"2025-03-23T12:06:48.258473Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngjabach\u001b[0m (\u001b[33mngjabach-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom transformers import DataCollatorForSeq2Seq\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel_name = 'facebook/bart-large'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:06:48.260433Z","iopub.execute_input":"2025-03-23T12:06:48.260831Z","iopub.status.idle":"2025-03-23T12:07:16.481668Z","shell.execute_reply.started":"2025-03-23T12:06:48.260809Z","shell.execute_reply":"2025-03-23T12:07:16.480336Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1582daa4d514ef2a4acef11d4244fe6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54aaad07fc5470bba6b9f0c5590ff14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99e94c205694498b914ef05efbf6ca83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dc385a60fa14c9584826ff62df0c8c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb65af60b5834417a211b2b05d1603b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb06449ecfe847cf9e6436b58513b21b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"csv\", data_files='/kaggle/input/qag-wop/QAG_Train_wop.csv')\n\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:07:16.483975Z","iopub.execute_input":"2025-03-23T12:07:16.485874Z","iopub.status.idle":"2025-03-23T12:07:17.570450Z","shell.execute_reply.started":"2025-03-23T12:07:16.485839Z","shell.execute_reply":"2025-03-23T12:07:17.569810Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8498b962fc93450894c5442bafd7c9ff"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'context'],\n        num_rows: 2803\n    })\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def get_features(batch):\n    encodings = tokenizer(batch['question'], \n                          text_target=batch['context'], \n                          max_length=1024, truncation=True)\n    \n    return {\"input_ids\": encodings[\"input_ids\"],\n            \"attention_mask\": encodings[\"attention_mask\"],\n            \"labels\": encodings[\"input_ids\"]}\n\ndataset_enc = dataset.map(get_features, batched=True)\ncolumns = ['input_ids', 'labels', 'attention_mask']\ndataset_enc.set_format(type='torch', columns=columns)\n\nprint(dataset_enc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:07:17.571926Z","iopub.execute_input":"2025-03-23T12:07:17.572415Z","iopub.status.idle":"2025-03-23T12:07:18.005602Z","shell.execute_reply.started":"2025-03-23T12:07:17.572391Z","shell.execute_reply":"2025-03-23T12:07:18.004630Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2803 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8ae8937a505477398e72d297dc0f3ca"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'context', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2803\n    })\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    run_name='bart-large-finetuning',\n    output_dir='./results',\n    logging_dir='./logs',\n    per_device_train_batch_size=1,\n    logging_steps=200,\n    num_train_epochs=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    learning_rate=5e-5,\n    max_grad_norm=1.0,\n    gradient_accumulation_steps=16,\n    fp16=True\n)\n\ntrainer = Trainer(model=model,\n                args=training_args,\n                processing_class=tokenizer,\n                data_collator=data_collator,\n                train_dataset=dataset_enc['train'])\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:07:18.006464Z","iopub.execute_input":"2025-03-23T12:07:18.006799Z","iopub.status.idle":"2025-03-23T12:40:29.587190Z","shell.execute_reply.started":"2025-03-23T12:07:18.006768Z","shell.execute_reply":"2025-03-23T12:40:29.586123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250323_120720-loi00tj6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface/runs/loi00tj6' target=\"_blank\">bart-large-finetuning</a></strong> to <a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface' target=\"_blank\">https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface/runs/loi00tj6' target=\"_blank\">https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface/runs/loi00tj6</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1400' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1400/1400 33:00, Epoch 7/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.112400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.073400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.163900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.182700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.082600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.083200</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.030000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1400, training_loss=0.10404654775347029, metrics={'train_runtime': 1989.2767, 'train_samples_per_second': 11.272, 'train_steps_per_second': 0.704, 'total_flos': 531998784061440.0, 'train_loss': 0.10404654775347029, 'epoch': 7.95897252943275})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dialogue = \"Introduce yourself as detailed as possible.\"\n\ninput_ids = tokenizer(dialogue, return_tensors='pt', \n                      max_length=1024, truncation=True).input_ids.to(device)\noutput = model.generate(input_ids, max_length=1024, early_stopping=False)\n\nsummary = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(f\"Summary: {summary}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:40:29.588222Z","iopub.execute_input":"2025-03-23T12:40:29.588573Z","iopub.status.idle":"2025-03-23T12:40:30.361573Z","shell.execute_reply.started":"2025-03-23T12:40:29.588522Z","shell.execute_reply":"2025-03-23T12:40:30.360673Z"}},"outputs":[{"name":"stdout","text":"Summary: Introduce yourself as detailed as possible.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model.save_pretrained(\"bart-baseline\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:40:30.362404Z","iopub.execute_input":"2025-03-23T12:40:30.362778Z","iopub.status.idle":"2025-03-23T12:40:34.286820Z","shell.execute_reply.started":"2025-03-23T12:40:30.362739Z","shell.execute_reply":"2025-03-23T12:40:34.285703Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink('bart-baseline/model.safetensors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T12:45:58.107678Z","iopub.execute_input":"2025-03-23T12:45:58.108000Z","iopub.status.idle":"2025-03-23T12:45:58.116260Z","shell.execute_reply.started":"2025-03-23T12:45:58.107973Z","shell.execute_reply":"2025-03-23T12:45:58.115389Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/bart-baseline/model.safetensors","text/html":"<a href='bart-baseline/model.safetensors' target='_blank'>bart-baseline/model.safetensors</a><br>"},"metadata":{}}],"execution_count":11}]}