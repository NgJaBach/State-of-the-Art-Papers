{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11125995,"sourceType":"datasetVersion","datasetId":6938589}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nwandb_key = UserSecretsClient().get_secret(\"wannabe\")\nwandb.login(key=wandb_key)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T07:11:21.684266Z","iopub.execute_input":"2025-03-24T07:11:21.684589Z","iopub.status.idle":"2025-03-24T07:11:29.376617Z","shell.execute_reply.started":"2025-03-24T07:11:21.684534Z","shell.execute_reply":"2025-03-24T07:11:29.375419Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngjabach\u001b[0m (\u001b[33mngjabach-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nimport torch\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel_name = 'facebook/bart-large'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T07:11:29.377897Z","iopub.execute_input":"2025-03-24T07:11:29.378427Z","iopub.status.idle":"2025-03-24T07:11:39.832143Z","shell.execute_reply.started":"2025-03-24T07:11:29.378395Z","shell.execute_reply":"2025-03-24T07:11:39.830683Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\nclass TokenDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n        return item\n    def __len__(self):\n        return len(self.labels['input_ids'])\n\ndef tokenize_data(train_question, train_context):\n    encodings = tokenizer(train_context, truncation=True, padding=True, max_length = 512)\n    decodings = tokenizer(train_question, truncation=True, padding=True, max_length = 512)\n    dataset_tokenized = TokenDataset(encodings, decodings)\n    return dataset_tokenized\n\ndf = pd.read_csv(\"/kaggle/input/qag-wop/QAG_Train_wop.csv\")\ndf.rename(columns = {'question':'question', 'context':'context'}, inplace = True)\ndf.keys()\n\ntrain_question, train_context = (list(df['question'])), (list(df['context']))\ntrain_data = tokenize_data(train_question, train_context)\n\nprint(train_data)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T07:11:39.835025Z","iopub.execute_input":"2025-03-24T07:11:39.836074Z","iopub.status.idle":"2025-03-24T07:11:40.404322Z","shell.execute_reply.started":"2025-03-24T07:11:39.836036Z","shell.execute_reply":"2025-03-24T07:11:40.403135Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<__main__.TokenDataset object at 0x7aceb8f0d720>\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    run_name='bart-large-finetuning',\n    output_dir='./results',\n    save_strategy=\"no\",\n    logging_strategy=\"steps\",\n    logging_steps=2000,\n    logging_dir=None,\n    per_device_train_batch_size=1,\n    num_train_epochs=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    fp16=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    processing_class=tokenizer,\n    train_dataset=train_data\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"bart-baseline\")","metadata":{"execution":{"iopub.status.busy":"2025-03-24T07:11:40.405638Z","iopub.execute_input":"2025-03-24T07:11:40.405905Z","iopub.status.idle":"2025-03-24T08:54:34.715187Z","shell.execute_reply.started":"2025-03-24T07:11:40.405884Z","shell.execute_reply":"2025-03-24T08:54:34.714427Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250324_071141-rv9ygaow</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface/runs/rv9ygaow' target=\"_blank\">bart-large-finetuning</a></strong> to <a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface' target=\"_blank\">https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface/runs/rv9ygaow' target=\"_blank\">https://wandb.ai/ngjabach-hanoi-university-of-science-and-technology/huggingface/runs/rv9ygaow</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22424' max='22424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22424/22424 1:42:42, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2000</td>\n      <td>1.231300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.296900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.269900</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.211200</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.163100</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.110500</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.090500</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.059700</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.050000</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.039000</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.022200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dialogue = \"Introduce yourself as detailed as possible.\"\n\ninput_ids = tokenizer(dialogue, return_tensors='pt', \n                      max_length=1024, truncation=True).input_ids.to(device)\noutput = model.generate(input_ids, max_length=1024, early_stopping=False)\n\nsummary = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(f\"Summary: {summary}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T08:54:34.716143Z","iopub.execute_input":"2025-03-24T08:54:34.716488Z","iopub.status.idle":"2025-03-24T08:54:35.240111Z","shell.execute_reply.started":"2025-03-24T08:54:34.716413Z","shell.execute_reply":"2025-03-24T08:54:35.239131Z"}},"outputs":[{"name":"stdout","text":"Summary: What do you mean by introducing yourself?\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink('bart-baseline/model.safetensors')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T08:55:30.904660Z","iopub.execute_input":"2025-03-24T08:55:30.904969Z","iopub.status.idle":"2025-03-24T08:55:30.913261Z","shell.execute_reply.started":"2025-03-24T08:55:30.904943Z","shell.execute_reply":"2025-03-24T08:55:30.912362Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/bart-baseline/model.safetensors","text/html":"<a href='bart-baseline/model.safetensors' target='_blank'>bart-baseline/model.safetensors</a><br>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}