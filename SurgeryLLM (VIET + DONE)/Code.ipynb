{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "d = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    # base_url=\"https://api.llama-api.com/\"\n",
    ")\n",
    "\n",
    "def ask_gpt(prompt: str, system: str, model=\"gpt-4o\") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        # model=\"llama3.2-3b\",\n",
    "        # model=\"llama3.3-70b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": system\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        # max_tokens=512\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "sys_res = \"Read the context, patient record, and answer the task question. If you don't know, just say you don't know.\"\n",
    "\n",
    "sys_key = \"Extract as much keywords and keyphrases most related to the task from the record as possible, but concisely and raw text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin chunking...\n",
      "Done!\n",
      "Begin chunking...\n",
      "Done!\n",
      "Begin chunking...\n",
      "Done!\n",
      "Begin chunking...\n",
      "Done!\n",
      "Begin vector storing...\n",
      "Done vector storing!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def chunking(sauce: str, chunk_size, chunk_overlap) -> str:\n",
    "    print(\"Begin chunking...\")\n",
    "    loader = PyPDFLoader(sauce)\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    print(\"Done!\")\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Path to the saved vector store\n",
    "faiss_index_path = \"/home/ngjabach/Documents/State-of-the-Art-Papers/SurgeryLLM (VIET + DONE)/faiss_index\"\n",
    "if os.path.exists(faiss_index_path):\n",
    "    vector_store = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    all_splits = []\n",
    "    all_splits = all_splits + chunking(\"ExternalDoc/labval.pdf\", 200, 10)\n",
    "    all_splits = all_splits + chunking(\"ExternalDoc/aortic.pdf\", 400, 20)\n",
    "    all_splits = all_splits + chunking(\"ExternalDoc/coronary.pdf\", 400, 20)\n",
    "    all_splits = all_splits + chunking(\"ExternalDoc/valvular.pdf\", 400, 20)\n",
    "\n",
    "    print(\"Begin vector storing...\")\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "    print(\"Done vector storing!\")\n",
    "\n",
    "    vector_store.save_local(faiss_index_path)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_res = '''\n",
    "---\n",
    "{reference}\n",
    "---\n",
    "A. Record: {record} \n",
    "B. Task: {task}\n",
    "C. Answer:\n",
    "'''\n",
    "\n",
    "prompt_key = '''\n",
    "A. Record: {record}\n",
    "B. Task: {task}\n",
    "'''\n",
    "\n",
    "task1 = \"Check the record and identify results outside of reference ranges.\"\n",
    "task2 = \"Identify unavailable preoperative tests.\"\n",
    "task3 = \"Surgical recommendation.\"\n",
    "task4 = \"Prepare sample operative notes.\"\n",
    "\n",
    "record = '''\n",
    "Patient: John Smith\n",
    "Age: 58, Male\n",
    "Medical History: Diabetes; multivessel coronary artery disease with left anterior descending (LAD) involvement\n",
    "Vital Signs: BP 140/85 mmHg, HR 80 bpm\n",
    "Laboratory Findings: Hemoglobin 9.0 g/dL\n",
    "Preoperative Workup: Basic clinical assessment, coronary angiography\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "Done compiling!\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    task: str #\n",
    "    record: str #\n",
    "    reference: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    print(\"Begin retriving!\")\n",
    "    messages = prompt_key.format(record=state[\"record\"], task=state[\"task\"])\n",
    "    keywords = ask_gpt(messages, sys_key)\n",
    "    log.append(\"\\n\\nDebug: Keywords\\n\\n\" + keywords) #\n",
    "    docs = retriever.invoke(keywords)\n",
    "    print(\"Done retrieving!\")\n",
    "    return {\"reference\": docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    print(\"Begin generating!\")\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"reference\"])\n",
    "    messages = prompt_res.format(record = state[\"record\"], task = state[\"task\"], reference = docs_content)\n",
    "    log.append(\"\\n\\nDebug: Prompt\\n\\n\" + messages) #\n",
    "    response = ask_gpt(messages, sys_res)\n",
    "    print(\"Done generating!\")\n",
    "    return {\"answer\": response}\n",
    "\n",
    "print(\"Compiling...\")\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "print(\"Done compiling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Task 1\n",
      "Begin retriving!\n",
      "Done retrieving!\n",
      "Begin generating!\n",
      "Done generating!\n",
      "Doing Task 2\n",
      "Begin retriving!\n",
      "Done retrieving!\n",
      "Begin generating!\n",
      "Done generating!\n",
      "Doing Task 3\n",
      "Begin retriving!\n",
      "Done retrieving!\n",
      "Begin generating!\n",
      "Done generating!\n",
      "Doing Task 4\n",
      "Begin retriving!\n",
      "Done retrieving!\n",
      "Begin generating!\n",
      "Done generating!\n"
     ]
    }
   ],
   "source": [
    "def logging(taskn: str, recordn: str, cnt: int):\n",
    "    log.clear()\n",
    "    print(f\"Doing Task {cnt}\")\n",
    "    response = graph.invoke({\"task\": taskn, \"record\": recordn})\n",
    "    log.append(\"\\n\\nDebug: Response\\n\\n\" + response[\"answer\"]) #\n",
    "    with open(f\"Result/Task{cnt}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"\\n\".join(log))\n",
    "\n",
    "logging(task1, record, 1)\n",
    "logging(task2, record, 2)\n",
    "logging(task3, record, 3)\n",
    "logging(task4, record, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
