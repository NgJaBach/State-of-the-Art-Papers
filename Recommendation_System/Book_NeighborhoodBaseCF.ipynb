{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating base:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1         1       5       874965758\n",
      "1        1         2       3       876893171\n",
      "2        1         3       4       878542960\n",
      "3        1         4       3       876893119\n",
      "4        1         5       3       889751712 \n",
      "\n",
      "Rating test:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1        20       4       887431883\n",
      "1        1        33       4       878542699\n",
      "2        1        61       4       878542420\n",
      "3        1       117       3       874965739\n",
      "4        1       155       2       878542201 \n",
      "\n",
      "Evaluating User-User CF with generic class...\n",
      "User-user CF, RMSE = 0.9766140289287265\n",
      "Evaluating Item-Item CF with generic class...\n",
      "Item-item CF, RMSE = 0.9688460838682366\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "class CollaborativeFiltering:\n",
    "    \"\"\"\n",
    "    Collaborative Filtering class for User-User or Item-Item predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, Y_data: np.ndarray, k: int, sim_func = cosine_similarity, mode='none') -> None:\n",
    "        \"\"\"\n",
    "        Initialize the collaborative filtering model.\n",
    "        \n",
    "        Parameters:\n",
    "        - Y_data: numpy array of shape (n_samples, 3), each row is [entity1_id, entity2_id, rating]\n",
    "        - k: number of nearest neighbors to consider for predictions\n",
    "        - sim_func: similarity function, default is cosine similarity\n",
    "        - mode: 'user' for User-User CF, 'item' for Item-Item CF\n",
    "        \"\"\"\n",
    "        self.Y_data = Y_data\n",
    "        self.k = k\n",
    "        self.sim_func = sim_func\n",
    "        self.Ybar = None\n",
    "        self.mode = mode\n",
    "        if mode == 'user':\n",
    "            self.n_entities = int(np.max(self.Y_data[:, 0])) + 1  # Number of unique users\n",
    "            self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "        elif mode == 'item':\n",
    "            self.n_entities = int(np.max(self.Y_data[:, 1])) + 1  # Number of unique items\n",
    "            self.n_users = int(np.max(self.Y_data[:, 0])) + 1\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be 'user' or 'item'\")\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Normalize the data and compute the similarity matrix.\n",
    "        \"\"\"\n",
    "        if self.mode == 'user':\n",
    "            print(\"Evaluating User-User CF with generic class...\")\n",
    "            entities = self.Y_data[:, 0]  # Extract all entity IDs\n",
    "        else:  # mode == 'item'\n",
    "            print(\"Evaluating Item-Item CF with generic class...\")\n",
    "            entities = self.Y_data[:, 1]  # Extract all entity IDs\n",
    "        \n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mr = np.zeros((self.n_entities,))\n",
    "\n",
    "        # Normalize ratings for each entity\n",
    "        for e in range(self.n_entities):\n",
    "            ids = np.flatnonzero(entities == e)\n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            self.mr[e] = np.mean(ratings) if ids.size > 0 else 0\n",
    "            self.Ybar[ids, 2] = ratings - self.mr[e]\n",
    "\n",
    "        # Create a sparse matrix\n",
    "        if self.mode == 'user':\n",
    "            self.Ybar = sparse.coo_matrix(\n",
    "                (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])),\n",
    "                shape=(self.n_items, self.n_entities)\n",
    "            ).tocsr()\n",
    "        else:  # mode == 'item'\n",
    "            self.Ybar = sparse.coo_matrix(\n",
    "                (self.Ybar[:, 2], (self.Ybar[:, 0], self.Ybar[:, 1])),\n",
    "                shape=(self.n_users, self.n_entities)\n",
    "            ).tocsr()\n",
    "\n",
    "        # Compute similarity matrix\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def pred(self, e: int, other_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Predict the rating based on the mode.\n",
    "        \n",
    "        Parameters:\n",
    "        - e: entity ID (user or item)\n",
    "        - other_id: item ID (if mode='user') or user ID (if mode='item')\n",
    "        \n",
    "        Returns:\n",
    "        - Predicted rating\n",
    "        \"\"\"\n",
    "        if self.mode == 'user': # Find users who rated the item\n",
    "            ids = np.flatnonzero(self.Y_data[:, 1] == other_id)\n",
    "            entities_rated = self.Y_data[ids, 0]\n",
    "        else:  # mode == 'item' # Find items rated by the user\n",
    "            ids = np.flatnonzero(self.Y_data[:, 0] == other_id)\n",
    "            entities_rated = self.Y_data[ids, 1]\n",
    "\n",
    "        if len(entities_rated) == 0:\n",
    "            return self.mr[e]\n",
    "\n",
    "        # Similarities\n",
    "        sim = self.S[e, entities_rated]\n",
    "        k_actual = min(self.k, len(sim))\n",
    "        nns = np.argsort(sim)[-k_actual:]\n",
    "        nearest_s = sim[nns]\n",
    "        r = self.Ybar[other_id, entities_rated[nns]]\n",
    "\n",
    "        eps = 1e-8\n",
    "        return (r * nearest_s).sum() / (np.abs(nearest_s).sum() + eps) + self.mr[e]\n",
    "\n",
    "\n",
    "# Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "rating_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "rating_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Rating base:\\n', rating_base.head(), '\\n')\n",
    "print('Rating test:\\n', rating_test.head(), '\\n')\n",
    "\n",
    "rate_train = rating_base.to_numpy()\n",
    "rate_test = rating_test.to_numpy()\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "n_tests = rate_test.shape[0]\n",
    "\n",
    "# User-User CF\n",
    "cf_user = CollaborativeFiltering(rate_train, k=40, mode='user')\n",
    "cf_user.fit()\n",
    "\n",
    "SE_user = 0\n",
    "for n in range(n_tests):\n",
    "    pred = cf_user.pred(int(rate_test[n, 0]), int(rate_test[n, 1]))\n",
    "    SE_user += (pred - rate_test[n, 2]) ** 2 \n",
    "\n",
    "RMSE_user = np.sqrt(SE_user / n_tests)\n",
    "print('User-user CF, RMSE =', RMSE_user)\n",
    "\n",
    "# Item-Item CF\n",
    "cf_item = CollaborativeFiltering(rate_train, k=40, mode='item')\n",
    "cf_item.fit()\n",
    "\n",
    "SE_item = 0\n",
    "for n in range(n_tests):\n",
    "    pred = cf_item.pred(int(rate_test[n, 1]), int(rate_test[n, 0]))\n",
    "    SE_item += (pred - rate_test[n, 2]) ** 2 \n",
    "\n",
    "RMSE_item = np.sqrt(SE_item / n_tests)\n",
    "print('Item-item CF, RMSE =', RMSE_item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
